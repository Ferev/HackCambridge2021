{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import cv2\n",
    "from PIL import ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import glob\n",
    "from moviepy.editor import *\n",
    "from PIL import Image as Img\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Create face detector\n",
    "mtcnn = MTCNN(margin=20, keep_all=True, post_process=False, device=device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a video\n",
    "# v_cap = cv2.VideoCapture('./input.mp4')\n",
    "# v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# destination_name = lambda x: os.path.join('frames', x)\n",
    "\n",
    "# # Loop through video\n",
    "# batch_size = 32\n",
    "# frames = []\n",
    "# boxes = []\n",
    "# landmarks = []\n",
    "# all_frames = []\n",
    "# probs = []\n",
    "# for i in tqdm(range(v_len)):\n",
    "    \n",
    "#     # Load frame\n",
    "#     success, frame = v_cap.read()\n",
    "#     if not success:\n",
    "#         continue\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     frame = Img.fromarray(frame)\n",
    "#     frame.save(destination_name('img_{}.jpg'.format(i)))\n",
    "    \n",
    "#     # When batch is full, detect faces and reset batch list\n",
    "#     if len(frames) >= batch_size:\n",
    "#         batch_boxes, p, batch_landmarks = mtcnn.detect(frames, landmarks=True)\n",
    "#         boxes.extend(batch_boxes)\n",
    "#         probs.extend(p)\n",
    "#         frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "# ImageNet labels\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to preprocess the image so that it can be inputted in MobileNetV2\n",
    "def preprocess(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    image = image[None, ...]\n",
    "    return image\n",
    "\n",
    "# Helper function to extract labels from probability vector\n",
    "def get_imagenet_label(probs):\n",
    "  return decode_predictions(probs, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = pretrained_model(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob(os.path.join('frames', \"*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b488d8ec66a43cb9a57a106a22d77b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_path in tqdm(image_paths):\n",
    "    ix = image_path.split('.')[0].split('_')[1]\n",
    "    image_raw = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image_raw)\n",
    "\n",
    "    image = preprocess(image)\n",
    "    image_probs = pretrained_model.predict(image)\n",
    "    labrador_retriever_index = 208\n",
    "    label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
    "    label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
    "\n",
    "    perturbations = create_adversarial_pattern(image, label)\n",
    "    adv_x = image + 0.01*perturbations\n",
    "    tf.keras.preprocessing.image.save_img('processed/' + ix.zfill(8) + '_.png',adv_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob(os.path.join('processed', \"*\"))\n",
    "image_paths = sorted(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ece8b2982a4fe59053bdf69ecbfe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = cv2.VideoWriter('processed_temp.mp4', cv2.VideoWriter_fourcc(*'MJPG'), 25, (1280,720))\n",
    "for img_path in tqdm(image_paths):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = Img.fromarray(img)\n",
    "    img = img.resize((1280, 720))\n",
    "    img = np.array(img)\n",
    "    writer.write(img)\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, array([None], dtype=object))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = Img.fromarray(img)\n",
    "frame.resize((1280, 720))\n",
    "mtcnn.detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hc2021",
   "language": "python",
   "name": "hc2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
